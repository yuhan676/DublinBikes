{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61dc117-86ce-4d99-b3b6-bccfbf3f5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk as nl\n",
    "import sklearn as mp\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import requests as rq\n",
    "import sqlalchemy as sqla\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "from sklearn import metrics\n",
    "import matplotlib as mpl\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sktime.datasets import load_airline\n",
    "dpi, w, h = 160, 12, 8\n",
    "mpl.rcParams.update({'figure.figsize': (w, h)})\n",
    "mpl.rcParams.update({'figure.dpi': dpi})\n",
    "import json\n",
    "# import seaborn as sns\n",
    "# Allows plots to appear directly in the notebook.\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f3529f-e3ae-4c64-af71-01f626c06825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYTHONXEXC'] = 'off'\n",
    "print(os.environ['PYTHONXEXC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03adcbfb-b5ab-4a54-a4bb-01b6f464ed96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONXEXC=off\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONXEXC=off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63957656-a74a-49a2-8a47-8866e580bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# capture magic method allows to hide the output cell\n",
    "# define tables here so that they would be visible during the model prediciton creation\n",
    "CurrentWeather = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS CurrentWeather (\n",
    "        time_update DATETIME NOT NULL,\n",
    "        current_weather_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        feels_like DECIMAL(5, 2) NOT NULL,\n",
    "        temperature_min DECIMAL(5, 2) NOT NULL,\n",
    "        temperature_max DECIMAL(5, 2) NOT NULL,\n",
    "        weather_description VARCHAR(120),\n",
    "        wind_speed DECIMAL(5, 2) NOT NULL,\n",
    "        wind_gust DECIMAL(5, 2) NOT NULL DEFAULT 0\n",
    "    );\n",
    "\"\"\"\n",
    "# Copying the extreme weather table here, to merge timestamp later\n",
    "ExtremeWeather = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ExtremeWeather (\n",
    "        time_update DATETIME NOT NULL,\n",
    "        extreme_weather_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        temp_min DECIMAL(5, 2) NOT NULL,\n",
    "        temp_max DECIMAL(5, 2) NOT NULL,\n",
    "        wind_speed DECIMAL(5, 2) NOT NULL,\n",
    "        gust_speed DECIMAL(5, 2) NOT NULL DEFAULT 0,\n",
    "        rain_3h DECIMAL(5, 2) NOT NULL DEFAULT 0\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "FiveDayPrediction = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS FiveDayPrediction (\n",
    "        time_update DATETIME NOT NULL,\n",
    "        forecast_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        temp_min DECIMAL(5, 2) NOT NULL,\n",
    "        temp_max DECIMAL(5, 2) NOT NULL,\n",
    "        wind_speed DECIMAL(5, 2) NOT NULL,\n",
    "        gust DECIMAL(5, 2) NOT NULL DEFAULT 0,\n",
    "        rain_3h DECIMAL(5, 2) NOT NULL DEFAULT 0\n",
    "    );\n",
    "\"\"\"\n",
    "# static station data\n",
    "Station = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS station (\n",
    "        number INT NOT NULL,\n",
    "        name VARCHAR (120),\n",
    "        address VARCHAR(256),\n",
    "        banking TINYINT(1), \n",
    "        bonus TINYINT(1),\n",
    "        position_lat REAL,\n",
    "        position_lng REAL, \n",
    "        PRIMARY KEY (number)\n",
    "    );\n",
    "\"\"\"\n",
    "# Dynamic station data\n",
    "StationStatus = \"\"\"\n",
    "    DROP TABLE IF EXISTS station_status;\n",
    "    CREATE TABLE station_status (\n",
    "        station_number INT NOT NULL,\n",
    "        status VARCHAR(256) NOT NULL,\n",
    "        last_update DATETIME,\n",
    "        empty_stands_number INT,\n",
    "        total_bikes INT,\n",
    "        mechanical_bikes INT,\n",
    "        electrical_internal_battery_bikes INT,\n",
    "        electrical_removable_battery_bikes INT,\n",
    "        PRIMARY KEY (station_number, last_update),\n",
    "        FOREIGN KEY (station_number) REFERENCES station(number)\n",
    "        ON DELETE CASCADE\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654ef7d-fe29-421c-b35b-2f61694874b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Read database connection details from config.json\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    connection_url = config.get('url')\n",
    "    if not connection_url:\n",
    "        raise ValueError(\"Connection URL is missing in the configuration file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: config.json file not found.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Unable to decode config.json file. Make sure it's in proper JSON format.\")\n",
    "    exit()\n",
    "except KeyError:\n",
    "    print(\"Error: 'url' key is missing in the config.json file.\")\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # Attempt to establish connection to the database\n",
    "    engine = create_engine(connection_url)\n",
    "    connection = engine.connect()\n",
    "    print(\"Connection established successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred while establishing the connection:\", e)\n",
    "    exit()\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857b0d5-c655-4c4f-b6b2-d32c309d6c1d",
   "metadata": {},
   "source": [
    "<h2><center>Merging Timestamps</center></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8c720-eaee-4544-a528-9b884db91f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = pd.read_sql('station', engine)\n",
    "df_station = pd.read_sql('station_status', engine)\n",
    "df_weather = pd.read_sql('CurrentWeather', engine)\n",
    "df_weather = pd.read_sql('FiveDayPrediction', engine)\n",
    "df_weather = pd.read_sql('ExtremeWeather', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe3941-6b58-42f7-ba1e-3c6242f7853c",
   "metadata": {},
   "source": [
    "# tables = ['CurrentWeather', 'ExtremeWeather', 'FiveDayPrediction', 'Station', 'StationStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568ec20d-3f2b-491c-b8a9-01ab06d5b981",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Histograms for numerical variables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m numerical_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numerical_cols:\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Histograms for numerical variables\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[col], bins=20, kde=True)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Bar plot for categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f'Bar plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Data Relationships\n",
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots for relationships\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=col, y=df.columns[-1], data=df)\n",
    "    plt.title(f'Scatter plot of {col} vs. {df.columns[-1]}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(df.columns[-1])\n",
    "    plt.show()\n",
    "\n",
    "# Outliers and Anomalies\n",
    "# Box plots for outlier detection\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Box plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6419b53-3c55-4a43-8860-2544da1a5095",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data Inspection\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Display the first 5 rows of the DataFrame\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the shape of the DataFrame (number of rows and columns)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Data Inspection\n",
    "# Display the first 5 rows of the DataFrame\n",
    "df.head()\n",
    "# Display the shape of the DataFrame (number of rows and columns)\n",
    "df.shape\n",
    "# Display information about the DataFrame, including data types and memory usage\n",
    "df.info()\n",
    "# Count the number of duplicate rows in the DataFrame\n",
    "df.duplicated().sum()\n",
    "# Descriptive Statistics\n",
    "df.describe()\n",
    "# types of the data \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0627dd30-55b4-424b-b15f-d11df38a9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below is based on code presented in module COMP47350 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4e12b2-2d7e-4524-985d-e3694083a092",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quality_report\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m quality_report \u001b[38;5;241m=\u001b[39m check_data_quality(df)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing Values:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(quality_report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_values\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def check_data_quality(df):\n",
    "    \"\"\"\n",
    "    Check the data quality of a DataFrame for missing, unusual, and unknown values.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary containing information about missing, unusual, and unknown values.\n",
    "    \"\"\"\n",
    "    quality_report = {}\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    quality_report['missing_values'] = missing_values[missing_values > 0]\n",
    "    \n",
    "    # Check for unusual values\n",
    "    unusual_values = {}\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numerical_cols:\n",
    "        unusual_values[col] = df[col].describe()\n",
    "    \n",
    "    quality_report['unusual_values'] = unusual_values\n",
    "    \n",
    "    # Check for unknown values (if applicable)\n",
    "    # You need to define what constitutes an \"unknown\" value in your context\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Usage example\n",
    "quality_report = check_data_quality(df)\n",
    "print(\"Missing Values:\")\n",
    "print(quality_report['missing_values'])\n",
    "\n",
    "print(\"\\nUnusual Values:\")\n",
    "for col, stats in quality_report['unusual_values'].items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2edc79b-8ced-4b0c-93d6-05db88067907",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check the shape of the DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m num_rows, num_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_rows)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_cols)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the shape of the DataFrame\n",
    "num_rows, num_cols = df.shape\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a29889-cf5c-4fc4-8f27-6360006ac7a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba921a2d-c109-4cef-8027-19b30afc67d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ad6cbb8-f869-48a3-b5f3-d72546320c4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert data types to relevant data types\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_update\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_max\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgust_speed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrain_3h\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert data type to category for these columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert data types to relevant data types\n",
    "categorical_columns = df[['time_update', 'temp_min', 'temp_max','wind_speed', 'gust_speed', 'rain_3h']].columns\n",
    "# Convert data type to category for these columns\n",
    "for column in categorical_columns:\n",
    "    df[column] = df[column].astype('category')  \n",
    "\n",
    "continuous_columns = df.select_dtypes(['int64']).columns\n",
    "datetime_columns = df.select_dtypes(['datetime64[ns]']).columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76092503-b6ad-4312-b400-241433ca4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Var_Corr = df.corr()\n",
    "# plt.subplots(figsize=(50, 50))\n",
    "# plot the heatmap and annotation on it\n",
    "#sns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5076da-1df7-4023-9806-8da3c3c3c4b2",
   "metadata": {},
   "source": [
    "username = api_keys.DB_USER\n",
    "password = api_keys.DB_PASS\n",
    "url = api_keys.DB_URL\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{0}:{1}@{2}\".format(DB_USER, DB_PASS, DB_URL), echo=True) \n",
    "connection = engine.connect()\n",
    "\n",
    "statement = \"\"\"SELECT dayname(availability.time_queried) as dayquery, hour(availability.time_queried) as hourquery, available_bikes,temp,wind_speed,pressure,humidity,weather_main FROM dublin_bikes.availability, dublin_bikes.weather_current\n",
    "where availability.number = 2 && weather_current.station_number = 2 && timestampdiff(MINUTE,availability.time_queried, weather_current.time_queried) < 5 && timestampdiff(MINUTE,availability.time_queried, weather_current.time_queried) > 0\n",
    "order by availability.time_queried;\n",
    "\"\"\" \n",
    "# create select statement for stations table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05e5fc-9f5c-4557-a1e2-a848dba27890",
   "metadata": {},
   "source": [
    "split to 80 and 20/20 or 10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92488b-a271-4ad8-bcd8-8d9120560db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b1f2ce7-b4cb-40f4-b992-c94937dad2f9",
   "metadata": {},
   "source": [
    "df_availability = pd.read_sql('availability', engine)\n",
    "df_station = pd.read_sql('station', engine)\n",
    "df_station = pd.read_sql('station', engine)\n",
    "df_weather = pd.read_sql('hourly', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915234b7-cab3-4981-9fa2-9cc43aa1c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "SHOW COLUMNS FROM CurrentWeather;\n",
    "SHOW COLUMNS FROM ExtremeWeather;\n",
    "SHOW COLUMNS FROM FiveDayPrediction;\n",
    "SHOW COLUMNS FROM station;\n",
    "SHOW COLUMNS FROM station_status;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae4ca4-8fc1-4663-9e93-29262ed1ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT ss.station_number,\n",
    "       ss.last_update,\n",
    "       ss.status,\n",
    "       ss.empty_stands_number,\n",
    "       ss.total_bikes,\n",
    "       ss.mechanical_bikes,\n",
    "       ss.electrical_internal_battery_bikes,\n",
    "       ss.electrical_removable_battery_bikes,\n",
    "       s.name,\n",
    "       s.address,\n",
    "       s.banking,\n",
    "       s.bonus,\n",
    "       s.position_lat,\n",
    "       s.position_lng,\n",
    "       cw.feels_like,\n",
    "       cw.temperature_min,\n",
    "       cw.temperature_max,\n",
    "       cw.weather_description,\n",
    "       cw.wind_speed,\n",
    "       cw.wind_gust,\n",
    "       fdp.temp_min AS forecast_temp_min,\n",
    "       fdp.temp_max AS forecast_temp_max,\n",
    "       fdp.wind_speed AS forecast_wind_speed,\n",
    "       fdp.gust AS forecast_gust,\n",
    "       fdp.rain_3h AS forecast_rain_3h\n",
    "FROM station_status ss\n",
    "JOIN station s ON ss.station_number = s.number\n",
    "JOIN currentweather cw ON ss.last_update = cw.time_update\n",
    "JOIN FiveDayPrediction fdp ON ss.last_update = fdp.time_update;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
